{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we first read in the data from the csv file, then shuffle the rows with a fixed random seed number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv('iris.csv', names=[\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\", \"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1. (15 pts)\n",
    "Create the input data and the target. The input data containts four columns [\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\"], the target contains the \"class\" column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"you fill in here\"\n",
    "target = \"you fill in here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use sklearn's train_test_split to create our training and test data. `X_train` is the input data for training, `y_train` is the target for training, while `X_test` is the input data for testing and `y_test` is the target for testing. Here we set the size of test size as 40% of data. (This step is done for you so you don't need to do anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, target, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2. (15 pts)\n",
    "Train a KNN (K=3) model on the training data prepared in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# you fill in here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3. (20 pts)\n",
    "Evaluate the model using the test set and print out the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# you fill in here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Task. \n",
    "\n",
    "Split the data into 80% training and 20% test. Train and evaluate the 3NN model. Discuss the difference from the previous results with a larger test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit this file to your submission repo, with a commit message 'quiz 1 submission'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eba38789ab565d76f074e8fa97ecc7da63eb4a5e1ba28cc348f16f5285783ca7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
